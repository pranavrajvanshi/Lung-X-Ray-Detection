{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import cv2                 \nimport numpy as np         \nimport os                  \nfrom random import shuffle\nimport tensorflow as tf \nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport glob as gb\nfrom tensorflow.keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read DataSet\nTrianImage=\"/kaggle/input/chest-xray-covid19-pneumonia/Data/train/\"\nTestImage=\"/kaggle/input/chest-xray-covid19-pneumonia/Data/test/\"\n\n\nprint(TrianImage)\nprint(TestImage)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to get all image names in train file\nPneumonaimages = os.listdir(TrianImage + \"/PNEUMONIA\")\nNormalimages = os.listdir(TrianImage + \"/NORMAL\")\nCOVID19images = os.listdir(TrianImage + \"/COVID19\")\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # **Explore the Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot to show the size of some image\n#plot PNEUMONIA\nplt.figure(figsize=(20,10))\nfor i in range(6):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(plt.imread(os.path.join(TrianImage + \"/PNEUMONIA\",Pneumonaimages[i])),cmap='gray')\n    plt.title(\"PNEUMONIA\")\n    \nplt.show()\n#plot NORMAL\nplt.figure(figsize=(20,10))\nfor i in range(6):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(plt.imread(os.path.join(TrianImage + \"/NORMAL\",Normalimages[i])),cmap='gray')\n    plt.title(\"NORMAL\")\n\nplt.show()\n#plot \nplt.figure(figsize=(20,10))\nfor i in range(6):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(plt.imread(os.path.join(TrianImage + \"/COVID19\",COVID19images[i])),cmap='gray')\n    plt.title(\"COVID19\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ImageDataGenerator (DataAugmentation )"},{"metadata":{},"cell_type":"markdown","source":"We also use the generator to transform the values in each batch so that their mean is $0$ and their standard deviation is 1.\nThis will facilitate model training by standardizing the input distribution"},{"metadata":{},"cell_type":"markdown","source":"The generator also converts our single channel X-ray images (gray-scale) to a three-channel format by repeating the values in the image across all channels.\nWe will want this because the pre-trained model that we'll use requires three-channel inputs."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n      samplewise_center=True,\n      samplewise_std_normalization= True,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      fill_mode='nearest'\n                                  )\n\n# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE \n# TRAIN GENERATOR.\ntrain_generator =train_datagen.flow_from_directory(\n     TrianImage,\n     batch_size= 256,\n     shuffle=shuffle,\n     target_size=(300, 300)\n\n)\n\ntest_generator =train_datagen.flow_from_directory(\n     TestImage,\n     batch_size= 50,\n     shuffle=shuffle,\n     target_size=(300, 300)\n\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainShape=train_generator.__getitem__(0)[0].shape\ntestShape=test_generator.__getitem__(0)[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shape of Data\nprint(\"Train Shape \\n\",trainShape)\nprint(\"Test Shape \\n\",testShape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nLabels={'NORMAL':0,'PNEUMONIA':1,'COVID19':2}\n\n# convert label to code\ndef getCode(label):\n    return Labels[label]\n\n\n# convert code to label \ndef getLabel(n):\n    for x,c in Labels.items():\n        if n==c:\n            return x\n        \n        \n        \n#Test        \nprint(getCode('COVID19'))\nprint(getLabel(1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore Data After DataAugmentation and standardizing "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(train_generator.__getitem__(0)[0][i])\n    plt.title(getLabel(np.argmax(train_generator.__getitem__(0)[1][i])) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Another Way To Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading image data\nimport glob as gb\nimport cv2  \nsizeImage=300 # to resize the all image as same size\n\n#to read all images from directory\ndef getData(Dir,sizeImage):\n    X=[]\n    y=[]\n    for folder in  os.listdir(Dir) : #to get the file name \n        files = gb.glob(pathname= str( Dir  +\"/\" +folder+ '//*.jpg' )) # to get the images\n        for file in files:\n                picture=cv2.imread(file) #  or plt.imread(file)\n                imageArray=cv2.resize(picture,(sizeImage,sizeImage))\n                X.append(list(imageArray))\n                y.append(getCode(folder))\n    X=np.array(X)\n    y=np.array(y)\n    return X,y\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get train data\nX_train, y_train = getData(TrianImage,sizeImage)\n# get test data\nX_test , y_test = getData(TestImage,sizeImage)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_train Shape        \",X_train.shape)\nprint(\"X_test Shape         \",X_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Convert y_train to categorical\ny_train=to_categorical(y_train,3)\nprint(\"y_train \",y_train.shape)\n\n\n\n#Convert y_train to categorical\ny_test=to_categorical(y_test,3)\nprint(\"y_test \",y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#load weight\nNetwork_Weight=\"/kaggle/input/densenet-keras/DenseNet-BC-169-32-no-top.h5\"\nprint(Network_Weight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sizeImage=300 \nfrom tensorflow.keras.applications.densenet import DenseNet169\npre_trained_model = DenseNet169(input_shape = (sizeImage, sizeImage, 3), \n                                include_top = False, \n                                weights = None)\npre_trained_model.load_weights(Network_Weight)\nfor layer in pre_trained_model.layers:\n    layer.trainable = False  #to make the layers to Freeze Weights\npre_trained_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import Model\nimport tensorflow as tf\n\nx = tf.keras.layers.Flatten()(pre_trained_model.output)\n\n#Full Connected Layers\nx = tf.keras.layers.Dense(512, activation='relu')(x)\n#Add dropout to avoid Overfit\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(256, activation='relu')(x)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n#Add dropout to avoid Overfit\nx = tf.keras.layers.Dropout(0.4)(x)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\n\n\nx=tf.keras.layers.Dense(3 , activation='sigmoid')(x)\n       \n\nmodel = Model( pre_trained_model.input, x) \n\nprint(model.summary())\nmodel.compile(optimizer='adam', loss=\"binary_crossentropy\",metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\nlr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n\nfilepath=\"transferlearning_weights.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nhistory = model.fit_generator(train_generator,steps_per_epoch=20,callbacks=[lr_reduce,checkpoint] ,\n         epochs=epochs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluate Model\nmodel.evaluate(test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('modelCovid19___2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prediction\npred=model.predict(test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=[]\nfor i in range(26):\n    y_test.extend(test_generator.__getitem__(i)[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(y_test))\ny_test=np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=np.argmax(y_test,axis=1)\npred= np.argmax(pred,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"pred \\n\",len(pred))\nprint(\"y_test \\n\",len(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"y_test \\n\",y_test)\nprint(\"pred \\n\",pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#confusion_matrix to check in accuracy \nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(pred,y_test)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nfor i in range(0,9):\n    \n    plt.subplot(3, 3, i + 1)\n    \n    plt.imshow(test_generator.__getitem__(0)[0][i],cmap='gray')\n    plt.title(f\"   Real: {getLabel(y_test[i])   } Vs  Predict: {getLabel(pred[i])}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lto load model\nfrom keras.models import load_model\nloadedModel=load_model(\"modelCovid19___2.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loadedModel.compile(optimizer='adam', loss=\"binary_crossentropy\",metrics=['accuracy'])\nloadedModel.evaluate(test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}